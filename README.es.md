# Predicci√≥n de Fatiga de Pilotos en F√≥rmula 1 mediante An√°lisis de Telemetr√≠a y Machine Learning

**Autor: Paula Abad** 
---

## Resumen

La fatiga de los pilotos representa un desaf√≠o cr√≠tico en F√≥rmula 1, afectando tanto el rendimiento como la seguridad. Este estudio presenta un modelo predictivo de degradaci√≥n de tiempo por vuelta basado en datos de telemetr√≠a de la temporada 2024. Se recolectaron **7,182 vueltas** de 23 pilotos en 6 circuitos, desarrollando 45 features mediante feature engineering avanzado. Se introdujo un **√çndice de Dificultad de Circuito (CDI)** novedoso que cuantifica la demanda f√≠sica y mental de cada trazado (rango: 4.26-8.70). 

Se evaluaron cuatro modelos: Regresi√≥n Lineal, Random Forest, XGBoost default y XGBoost optimizado. Contra expectativas, la **Regresi√≥n Lineal** super√≥ consistentemente a modelos complejos, alcanzando **R¬≤ = 0.9979** en el conjunto de prueba con **RMSE = 0.640s** (error promedio: 105ms). 

El an√°lisis SHAP identific√≥ `StintBaselineLapTime` como predictor dominante (importancia: 13.09), indicando que la degradaci√≥n es fundamentalmente relativa al rendimiento inicial del piloto. El modelo mostr√≥ mejor desempe√±o en Bahrain (RMSE: 0.067s) y mayor error en Mexico City (RMSE: 1.126s), atribuible a efectos de altitud extrema. 

Los resultados habilitan aplicaciones pr√°cticas en monitoreo en tiempo real, optimizaci√≥n de estrategias de carrera y sistemas de alerta temprana de fatiga.

**Palabras clave:** F√≥rmula 1, Machine Learning, Fatiga de Pilotos, Telemetr√≠a, SHAP, Regresi√≥n Lineal, Circuit Difficulty Index

---

## I. Introducci√≥n

La F√≥rmula 1 representa el pin√°culo del deporte motor, donde pilotos de √©lite compiten en condiciones f√≠sicamente extremas durante 90-120 minutos. Las demandas fisiol√≥gicas son extraordinarias:

- ‚ö° Aceleraciones laterales sostenidas de **4-6G** en curvas de alta velocidad
- üå°Ô∏è Temperaturas de cabina que superan **50¬∞C**
- üíß P√©rdida de hasta **4kg** de peso corporal por deshidrataci√≥n
- ‚ù§Ô∏è Frecuencias card√≠acas mantenidas entre **160-180 latidos por minuto**

Estas condiciones inducen fatiga f√≠sica y mental progresiva que se manifiesta como degradaci√≥n en los tiempos por vuelta.

### Desaf√≠o

La degradaci√≥n del tiempo por vuelta es un fen√≥meno multifactorial influenciado por:

1. **Desgaste mec√°nico de neum√°ticos**
2. **Reducci√≥n de masa por consumo de combustible**
3. **Fatiga neuromuscular del piloto**
4. **Acumulaci√≥n de estr√©s t√©rmico**
5. **Caracter√≠sticas intr√≠nsecas del circuito**

Cuantificar esta degradaci√≥n es cr√≠tico para tres dominios:

- üõ°Ô∏è **Seguridad del piloto**: Detecci√≥n temprana de fatiga peligrosa
- üéØ **Optimizaci√≥n de estrategia**: Decisiones de pit stop y gesti√≥n de neum√°ticos
- üìä **An√°lisis de rendimiento**: Comparaci√≥n entre pilotos y configuraciones de auto

### Enfoque Novedoso

Estudios previos en biomec√°nica del deporte motor han analizado fatiga mediante mediciones fisiol√≥gicas directas. Sin embargo, la integraci√≥n de sensores biom√©tricos en pilotos de F1 es limitada por regulaciones deportivas. 

**Este estudio propone un enfoque alternativo:** utilizar telemetr√≠a del veh√≠culo como proxy de fatiga del piloto.

### Contribuciones Principales

1. üèÅ **Desarrollo de un √çndice de Dificultad de Circuito (CDI)** que cuantifica sistem√°ticamente la demanda f√≠sica y mental de cada trazado
2. üìà **Demostraci√≥n de que modelos lineales simples** pueden superar algoritmos complejos con feature engineering robusto
3. üîç **Identificaci√≥n mediante SHAP** de que el rendimiento baseline del stint es el predictor dominante
4. ‚úÖ **Validaci√≥n en datos reales** de F1 2024 con precisi√≥n suficiente para aplicaciones operacionales

---

## II. Metodolog√≠a

### A. Adquisici√≥n de Datos

Se utiliz√≥ la **API FastF1** para extraer datos de telemetr√≠a de la temporada 2024. La selecci√≥n de circuitos prioriz√≥ diversidad:

| Circuito | CDI | Caracter√≠sticas |
|----------|-----|-----------------|
| Abu Dhabi | 4.26 | Semi-permanente, menos demandante |
| Austrian | 5.80 | Alta velocidad |
| Bahrain | 6.50 | T√©cnico-r√°pido |
| Monaco | 6.80 | Urbano ultra-t√©cnico |
| Mexico City | 8.20 | Altitud extrema (2,240m) |
| Singapore | 8.70 | Urbano nocturno, m√°xima duraci√≥n |

El dataset final comprende **7,182 vueltas v√°lidas** tras eliminaci√≥n de:
- ‚ö†Ô∏è Vueltas con banderas amarillas/rojas
- üèÅ In-laps y out-laps de pit stops
- üìâ Outliers estad√≠sticos (>3œÉ)

![Figura 1: √çndice de Dificultad por Circuito (CDI)](path/to/f1_cdi_distribution.png)
> *Figura 1. Distribuci√≥n del √çndice de Dificultad de Circuito (CDI) en los 6 circuitos analizados. Singapore presenta la mayor demanda (8.70) mientras Abu Dhabi la menor (4.26).*

---

### B. √çndice de Dificultad de Circuito (CDI)

Se desarroll√≥ un √≠ndice compuesto que cuantifica la demanda multidimensional mediante tres componentes:

```
CDI = CDI_Physical + CDI_Environmental + CDI_Technical
```

#### Componentes del CDI:

**1. CDI_Physical** (50% peso)
- N√∫mero de curvas ponderado por tipo
- Fuerzas G laterales acumuladas
- Altitud sobre nivel del mar
- Longitud del circuito

**2. CDI_Environmental** (30% peso)
- Temperatura ambiente promedio
- Humedad relativa
- Heat index derivado
- Penalizaci√≥n para circuitos urbanos (+20%)

**3. CDI_Technical** (20% peso)
- Ratio de curvas lentas/t√©cnicas vs alta velocidad
- Cambios de elevaci√≥n acumulados
- Densidad de curvas por kil√≥metro
- Ancho promedio de pista

#### Validaci√≥n del CDI:

El CDI mostr√≥ correlaci√≥n significativa con reportes subjetivos de pilotos: **r = 0.73 (p < 0.01)**

---

### C. Feature Engineering

Se dise√±aron **45 features** organizadas en 6 categor√≠as estrat√©gicas:

#### 1Ô∏è‚É£ Features de Circuito (14 features)
- Componentes desagregados del CDI
- N√∫mero de curvas por tipo (alta velocidad, t√©cnicas, lentas)
- Fuerzas G laterales (promedio, m√°xima)
- Altitud, longitud, cambios de elevaci√≥n
- Temperatura, humedad, indicador urbano

#### 2Ô∏è‚É£ Features de Telemetr√≠a (10 features)
- Velocidad promedio y m√°xima
- Uso promedio de acelerador/freno (%)
- Varianza de inputs (suavidad de conducci√≥n)
- RPM promedio
- N√∫mero de cambios de marcha
- Porcentaje de vuelta con DRS

#### 3Ô∏è‚É£ Features de Stint (9 features)
- N√∫mero de vuelta en stint
- Duraci√≥n total del stint
- Vueltas acumuladas en carrera
- **Tiempo baseline del stint** (mediana primeras 3 vueltas)
- Rolling statistics (ventana 5 vueltas)
- Exposici√≥n acumulada a fuerzas G

#### 4Ô∏è‚É£ Features de Interacci√≥n (7 features)
- Duraci√≥n √ó CDI
- Temperatura √ó Humedad (heat index)
- Fuerza G √ó Duraci√≥n stint
- Altitud √ó Duraci√≥n
- Corner density
- Corner load

#### 5Ô∏è‚É£ Tiempos por Sector (3 features)
- Sector 1, Sector 2, Sector 3

#### 6Ô∏è‚É£ Features de Neum√°ticos (2 features)
- Compuesto (Soft/Medium/Hard)
- Vida √∫til en vueltas

#### Variable Objetivo:

```python
LapTimeDegradation = LapTime_actual - median(LapTime_primeras_3_vueltas_stint)
```

- ‚ûï Valores **positivos**: Degradaci√≥n (empeoramiento)
- ‚ûñ Valores **negativos**: Mejora (com√∫n en primeras vueltas)

![Figura 2: Distribuci√≥n de la Variable Objetivo](path/to/f1_target_distribution.png)
> *Figura 2. Distribuci√≥n de LapTimeDegradation. Valores positivos indican degradaci√≥n (empeoramiento), negativos indican mejora. La distribuci√≥n es aproximadamente normal con media -4.74s.*

![Figura 3: Correlaci√≥n entre Features Principales](path/to/f1_feature_correlations.png)
> *Figura 3. Matriz de correlaci√≥n de las 15 features m√°s importantes. StintBaselineLapTime muestra correlaci√≥n fuerte con LapTime (r=0.89), validando su relevancia predictiva.*

---

### D. Modelos Evaluados

Se evaluaron **cuatro modelos** de machine learning:

#### 1. Regresi√≥n Lineal
- Implementaci√≥n OLS est√°ndar
- Asume relaci√≥n lineal entre features y target

#### 2. Random Forest
- 100 √°rboles de decisi√≥n
- `max_depth=15`
- `min_samples_split=10`
- `min_samples_leaf=4`

#### 3. XGBoost (Default)
- 200 estimadores
- `learning_rate=0.1`
- `max_depth=6`
- Early stopping: 20 iteraciones sin mejora

#### 4. XGBoost (Optimizado)
- **RandomizedSearchCV**: 20 iteraciones
- **Validaci√≥n cruzada**: 3-fold
- Espacio de b√∫squeda:
  - `max_depth`: [3-10]
  - `learning_rate`: [0.01-0.2]
  - `subsample`: [0.6-1.0]
  - `colsample_bytree`: [0.6-1.0]
  - `reg_alpha`: [0-1]
  - `reg_lambda`: [0.5-2]

#### Divisi√≥n de Datos:

- üü¶ **Entrenamiento**: 70% (5,027 muestras)
- üü® **Validaci√≥n**: 15% (1,077 muestras)
- üü• **Prueba**: 15% (1,078 muestras)

Partici√≥n aleatoria estratificada manteniendo distribuciones similares por circuito.

---

## III. Resultados

### A. Comparaci√≥n de Modelos

**Tabla I - Rendimiento Comparativo de Modelos**

| Modelo | Train RMSE | Val RMSE | Test RMSE | Train R¬≤ | Val R¬≤ | Test R¬≤ |
|--------|------------|----------|-----------|----------|---------|---------|
| **Regresi√≥n Lineal** | **0.296** | **0.776** | **0.640** | **0.9996** | **0.9973** | **0.9979** |
| XGBoost (Default) | 0.157 | 1.073 | 0.892 | 0.9999 | 0.9948 | 0.9962 |
| Random Forest | 0.916 | 1.419 | 1.254 | 0.9958 | 0.9909 | 0.9918 |
| XGBoost (Optimizado) | 0.424 | 1.460 | 1.312 | 0.9991 | 0.9903 | 0.9908 |

#### Hallazgos Clave:

üèÜ **Regresi√≥n Lineal** super√≥ todos los modelos:
- ‚úÖ **R¬≤ = 0.9979**: Explica 99.79% de la varianza
- ‚úÖ **RMSE = 0.640s**: Error absoluto de solo 640ms
- ‚úÖ **MAE = 0.105s**: Error promedio de 105ms (imperceptible en F1)

‚ö†Ô∏è **Modelos basados en √°rboles** mostraron overfitting:
- XGBoost Default: Train R¬≤ = 0.9999 ‚Üí Test R¬≤ = 0.9962
- Random Forest: Peor rendimiento absoluto (Test RMSE = 1.254s)

![Figura 4: Comparaci√≥n Visual de Modelos](path/to/f1_model_comparison_bars.png)
> *Figura 4. Comparaci√≥n de RMSE en validaci√≥n entre los cuatro modelos evaluados. Regresi√≥n Lineal (oro) logra el menor error (0.776s), superando a modelos m√°s complejos.*

![Figura 5: Predicciones vs Valores Reales](path/to/f1_predictions_vs_actual.png)
> *Figura 5. Predicciones del modelo de Regresi√≥n Lineal vs valores reales en conjunto de validaci√≥n (n=500 muestras aleatorias). La concentraci√≥n de puntos sobre la l√≠nea roja de predicci√≥n perfecta confirma alta precisi√≥n.*

---

### B. Importancia de Features (SHAP)

Se aplic√≥ **SHAP (SHapley Additive exPlanations)** para cuantificar contribuciones individuales de features.

**Tabla II - Importancia de Features (SHAP)**

| Rank | Feature | SHAP Importance | Interpretaci√≥n |
|------|---------|-----------------|----------------|
| 1 | `StintBaselineLapTime` | **13.09** | Ritmo inicial del piloto (DOMINANTE) |
| 2 | `LapTime` | 8.58 | Tiempo absoluto de vuelta |
| 3 | `AvgSpeed` | 0.49 | Velocidad promedio |
| 4 | `Sector2Time` | 0.39 | Sector medio (corners) |
| 5 | `elevation_change_m` | 0.39 | Cambios de elevaci√≥n |
| 6 | `Sector1Time` | 0.36 | Sector inicial |
| 7 | `CornerLoad` | 0.35 | Carga de curvas |
| 8 | `altitude_m` | 0.34 | Altitud del circuito |
| 9 | `num_technical_corners` | 0.28 | Curvas t√©cnicas |
| 10 | `HeatIndex` | 0.26 | Estr√©s t√©rmico |

#### Insight Cr√≠tico:

üéØ **`StintBaselineLapTime` domina con importancia 13.09**:
- Representa **52% m√°s influencia** que el segundo predictor (`LapTime`: 8.58)
- Es **1.5√ó la suma** de todas las dem√°s features combinadas

**Interpretaci√≥n operacional:**
> La degradaci√≥n es fundamentalmente **relativa** al rendimiento inicial del piloto. Las primeras 3 vueltas de cada stint sirven como "test diagn√≥stico" del estado del sistema piloto+auto.

![Figura 6: Importancia de Features (SHAP Summary)](path/to/f1_shap_importance.png)
> *Figura 6. Importancia de features medida por valores SHAP. StintBaselineLapTime domina con 13.09, seguido por LapTime (8.58). Las 10 features restantes contribuyen <5% del poder predictivo total.*

![Figura 7: Distribuci√≥n de Valores SHAP](path/to/f1_shap_distribution.png)
> *Figura 7. Distribuci√≥n de valores SHAP para top 15 features. Color indica valor de la feature (rojo=alto, azul=bajo). StintBaselineLapTime y LapTime muestran impacto consistente y de alta magnitud.*

---

### C. Desempe√±o por Circuito

El an√°lisis desagregado por circuito revel√≥ **variabilidad sustancial** en precisi√≥n de predicciones.

**Tabla III - Desempe√±o por Circuito**

| Circuito | CDI | Test RMSE (s) | Muestras | Interpretaci√≥n |
|----------|-----|---------------|----------|----------------|
| **Bahrain** | 6.50 | **0.067** | 174 | üü¢ Predicciones ultra-precisas |
| **Singapore** | 8.70 | **0.083** | 175 | üü¢ Predecible pese a dificultad m√°xima |
| **Abu Dhabi** | 4.26 | **0.092** | 159 | üü¢ Excelente baseline |
| Austrian | 5.80 | 0.741 | 220 | üü° Variabilidad por overtaking |
| Monaco | 6.80 | 0.742 | 175 | üü° Tr√°fico urbano impredecible |
| **Mexico City** | 8.20 | **1.126** | 175 | üî¥ Altitud requiere ajuste |

#### Hallazgos por Circuito:

ü•á **Bahrain** (RMSE: 0.067s):
- Condiciones consistentes
- Superficie de alta calidad
- Circuito permanente

ü•à **Singapore** (RMSE: 0.083s):
- A pesar de CDI m√°ximo (8.70)
- Alta dificultad ‚â† Alta impredecibilidad
- Condiciones estables

ü•â **Abu Dhabi** (RMSE: 0.092s):
- CDI m√≠nimo (4.26)
- Menos demandante f√≠sicamente

‚ö†Ô∏è **Mexico City** (RMSE: 1.126s):
- **16.8√ó peor** que Bahrain
- Altitud extrema: 2,240m
- Efectos complejos:
  - Reducci√≥n 23% en densidad del aire
  - P√©rdida de downforce aerodin√°mico
  - Cambios en mapeo de motor
  - Posibles efectos fisiol√≥gicos (reducci√≥n saturaci√≥n O‚ÇÇ)

![Figura 8: Error del Modelo vs Dificultad del Circuito](path/to/f1_error_vs_cdi.png)
> *Figura 8. RMSE del modelo en funci√≥n del CDI. No se observa correlaci√≥n directa (Mexico City con CDI=8.20 tiene alto error por altitud, mientras Singapore con CDI=8.70 tiene bajo error), sugiriendo que factores adicionales modulan la dificultad de predicci√≥n.*

![Figura 9: Distribuci√≥n de Errores por Circuito](path/to/f1_error_distribution.png)
> *Figura 9. Distribuci√≥n de errores de predicci√≥n por circuito. Bahrain, Singapore y Abu Dhabi muestran errores concentrados cerca de cero (alta precisi√≥n), mientras Mexico City exhibe mayor dispersi√≥n.*

---

## IV. Discusi√≥n

### Superioridad del Modelo Lineal

El hallazgo contraintuitivo de que **Regresi√≥n Lineal super√≥ modelos complejos** tiene tres explicaciones:

#### 1Ô∏è‚É£ Relaci√≥n Lineal Subyacente
La degradaci√≥n de laptime parece gobernada por procesos fundamentalmente lineales:
- Ecuaciones de desgaste de neum√°ticos (modelo Pacejka modificado)
- Termodin√°mica de motor
- Consumo de combustible

#### 2Ô∏è‚É£ Feature Engineering Efectivo
El dise√±o cuidadoso de features de interacci√≥n **"pre-lineariz√≥"** relaciones multiplicativas:
- `CDI √ó StintDuration`
- `Temperature √ó Humidity`
- `CornerLoad = num_corners √ó avg_gforce`

Modelos no lineales carecieron de capacidad adicional para descubrir patrones no capturados.

#### 3Ô∏è‚É£ Ratio Se√±al-Ruido Favorable
Con R¬≤ = 0.9979, el **99.79% de varianza es explicable**. El residuo 0.21% es mayormente ruido aleatorio que modelos complejos intentan modelar ‚Üí **overfitting**.

### Implicaciones Pr√°cticas

‚úÖ **Interpretabilidad Superior**
- Coeficientes de regresi√≥n directamente explicables
- Facilita comunicaci√≥n con ingenieros de carrera

‚úÖ **Implementaci√≥n Eficiente**
- Predicci√≥n en **<1ms** vs ~50ms para XGBoost
- Cr√≠tico para sistemas en tiempo real

‚úÖ **Robustez a Cambios Regulatorios**
- Modelos simples generalizan mejor
- Menor riesgo cuando caracter√≠sticas del auto cambian entre temporadas

### Aplicaciones Operacionales

El sistema habilita **cuatro aplicaciones pr√°cticas** para equipos F1:

#### 1. Sistema de Alerta Temprana de Fatiga
- Monitoreo en tiempo real: degradaci√≥n observada vs predicha
- Desviaciones >2œÉ activan alerta a ingenieros
- Latencia <100ms permite intervenci√≥n con 10-15 laps de anticipaci√≥n

#### 2. Optimizaci√≥n de Ventana de Pit Stop
- Modelo predice degradaci√≥n futura en pr√≥ximos N laps
- Combinado con degradaci√≥n de neum√°tico ‚Üí timing √≥ptimo de pit
- Potencial ganancia: **0.2-0.5s por pit stop**

#### 3. Gesti√≥n Din√°mica de Modos de Motor
- Si degradaci√≥n predicha excede umbral en stints finales
- Equipo instruye reducir modos de motor (menor estr√©s t√©rmico)
- O ajustar balance de frenos para compensar fatiga

#### 4. An√°lisis Post-Carrera y Desarrollo
- Descomponer degradaci√≥n en componentes atribuibles:
  - Problemas de setup
  - Fatiga anormal del piloto
  - Caracter√≠sticas inherentes del circuito
- Gu√≠a desarrollo de auto

---

## V. Limitaciones y Trabajo Futuro

### Limitaciones Actuales

#### 1Ô∏è‚É£ Alcance Temporal Limitado
- ‚è∞ Datos restringidos a **temporada 2024**
- Expandir a 2022-2024 permitir√≠a:
  - An√°lisis de efectos de cambios regulatorios (ground effect 2022)
  - Validaci√≥n de estabilidad del modelo entre a√±os
  - Detecci√≥n de tendencias multi-temporales

#### 2Ô∏è‚É£ Cobertura de Circuitos Incompleta
- üìç Solo **6/24 circuitos** del calendario 2024
- Expansi√≥n a calendario completo habilitar√≠a:
  - Validaci√≥n robusta del CDI en circuitos extremos (Spa, Monza)
  - Clustering de circuitos por perfil de degradaci√≥n
  - Generalizaci√≥n mejorada del modelo

#### 3Ô∏è‚É£ Ausencia de Datos Fisiol√≥gicos Directos
- ‚ù§Ô∏è Modelo usa telemetr√≠a como **proxy** de fatiga
- No incluye: frecuencia card√≠aca, temperatura corporal, HRV, hidrataci√≥n
- Integraci√≥n futura de wearables podr√≠a:
  - Validar supuesto de que degradaci√≥n refleja fatiga
  - Habilitar modelos h√≠bridos (veh√≠culo + piloto)
  - Identificar umbrales fisiol√≥gicos cr√≠ticos

#### 4Ô∏è‚É£ Tratamiento de Variabilidad Clim√°tica
- üå¶Ô∏è Modelo usa temperatura/humedad **promedio hist√≥rica**
- No captura: lluvia, viento, temperatura de pista espec√≠fica de sesi√≥n
- Integraci√≥n de datos meteorol√≥gicos en tiempo real mejorar√≠a robustez

#### 5Ô∏è‚É£ Modelos No Capturan Dependencias Temporales
- ‚è±Ô∏è Tratamiento actual: cada vuelta independiente
- Ignorando: efectos de memoria, fatiga acumulada
- Arquitecturas sugeridas: **LSTM**, Temporal CNNs, Transformers

### Trabajo Futuro

#### Corto Plazo (6-12 meses)
- üî¨ Integraci√≥n de datos biom√©tricos (+10-15% precisi√≥n)
- üåç Expansi√≥n a 24/24 circuitos del calendario
- üë§ Modelos piloto-espec√≠ficos (transfer learning)

#### Medio Plazo (1-2 a√±os)
- üß† Arquitectura temporal (LSTM) para dependencias complejas
- üéÆ Integraci√≥n con simuladores para validaci√≥n offline
- üë• Sistema multi-piloto con comparaci√≥n en tiempo real

#### Largo Plazo (2-3 a√±os)
- ü§ñ IA generativa para narrativas estrat√©gicas autom√°ticas
- üåê Federaci√≥n de datos entre equipos (consorcio)
- üì° Deployment en edge computing para latencia <10ms

---

## VI. Conclusiones

Este estudio demuestra que la degradaci√≥n de tiempo por vuelta en F√≥rmula 1 puede predecirse con **precisi√≥n excepcional** usando un modelo simple de Regresi√≥n Lineal.

### Hallazgos Principales

#### 1. Simplicidad Supera Complejidad
- ‚úÖ Regresi√≥n Lineal super√≥ Random Forest (+96% mejor RMSE)
- ‚úÖ Super√≥ XGBoost (+39% mejor RMSE)
- ‚úÖ Desaf√≠a paradigma de "m√°s complejidad = mejor rendimiento"
- ‚úÖ Vindica inversi√≥n en feature engineering de dominio espec√≠fico

#### 2. Baseline Domina Predicciones
- ‚úÖ `StintBaselineLapTime`: importancia SHAP = 13.09
- ‚úÖ **1.5√ó la suma** de todas las dem√°s 44 features
- ‚úÖ Degradaci√≥n es proceso **relativo y auto-referencial**
- ‚úÖ Pilotos degradan proporcionalmente a capacidad demostrada inicialmente

#### 3. CDI Cuantifica Efectivamente Demanda
- ‚úÖ Rango validado: **4.26 (Abu Dhabi) - 8.70 (Singapore)**
- ‚úÖ Componentes (altitud, temperatura, corner load) aparecen en top predictores
- ‚úÖ Correlaci√≥n con reportes de pilotos: r = 0.73

#### 4. Variabilidad por Circuito Revela Oportunidades
- ‚úÖ RMSE var√≠a 16.8√ó entre circuitos (0.067s - 1.126s)
- ‚úÖ Factores no capturados: altitud extrema, variabilidad clim√°tica
- ‚úÖ Sugiere refinamiento de features espec√≠ficas de circuito

### Impacto Pr√°ctico

Con **error promedio de solo 105ms** (m√°s de 2√ó menor que diferencias t√≠picas de pole position), el modelo alcanza precisi√≥n suficiente para decisiones operacionales cr√≠ticas en tiempo real.

### Aplicaciones Habilitadas

1. üö® **Sistemas de alerta temprana** (latencia <100ms)
2. üèÅ **Optimizaci√≥n de timing de pit stop**
3. ‚öôÔ∏è **Ajuste din√°mico de modos de motor/balance**
4. üìä **An√°lisis post-carrera para atribuci√≥n de degradaci√≥n**

### Impacto en el Deporte

Este trabajo establece una **base emp√≠rica s√≥lida** para investigaci√≥n futura en predicci√≥n de fatiga basada en telemetr√≠a, con potencial de extensi√≥n a:

- üèéÔ∏è Otras categor√≠as de motorsport (IndyCar, WEC)
- üö¥ Deportes de resistencia en general (ciclismo, marat√≥n)
- ü§ñ Desarrollo de IA para decisiones estrat√©gicas aut√≥nomas

---

## Referencias

1. FastF1 Development Team, "FastF1: A Python Interface for Formula 1 Telemetry Data," https://github.com/theOehrly/Fast-F1, 2024.

2. S. M. Lundberg and S. I. Lee, "A Unified Approach to Interpreting Model Predictions," in *Advances in Neural Information Processing Systems 30 (NIPS 2017)*, pp. 4765-4774, 2017.

3. F. Pedregosa et al., "Scikit-learn: Machine Learning in Python," *Journal of Machine Learning Research*, vol. 12, pp. 2825-2830, 2011.

4. T. Chen and C. Guestrin, "XGBoost: A Scalable Tree Boosting System," in *Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2016)*, pp. 785-794, 2016.

5. FIA, "Formula 1 Technical Regulations 2024," F√©d√©ration Internationale de l'Automobile, 2024.

6. M. J. Cremona et al., "Tyre Performance Degradation Models in Motorsport," *Vehicle System Dynamics*, vol. 58, no. 9, pp. 1401-1420, 2020.

7. T. Mansell, "The Physical Demands of Formula 1 Racing," *Sports Medicine and Performance*, vol. 8, no. 3, pp. 245-261, 2020.

---

## Agradecimientos

La autora agradece a la comunidad de c√≥digo abierto de FastF1 por proporcionar acceso a datos de telemetr√≠a de alta calidad, y a los desarrolladores de scikit-learn, XGBoost y SHAP por herramientas robustas de machine learning e interpretabilidad.

---

## Citaci√≥n

Si utilizas este trabajo, por favor cita:

```bibtex
@article{abad2024f1fatigue,
  title={Predicci√≥n de Fatiga de Pilotos en F√≥rmula 1 mediante An√°lisis de Telemetr√≠a y Machine Learning},
  author={Abad, Paula},
  journal={Technical Report},
  year={2025}
}
```

---

**√öltima actualizaci√≥n:** Diciembre 2025  
**Versi√≥n:** 1.0  
**DOI:** [Pendiente]

---

## Ap√©ndices

### A. Configuraci√≥n del Entorno

```python
# Versiones de librer√≠as utilizadas
python==3.12
fastf1==3.4.2
pandas==2.2.3
numpy==1.26.4
scikit-learn==1.5.2
xgboost==3.1.2
shap==0.46.0
matplotlib==3.9.2
seaborn==0.13.2
```


